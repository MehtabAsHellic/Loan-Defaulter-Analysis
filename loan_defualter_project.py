# -*- coding: utf-8 -*-
"""Untitled13.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tgiVjL0sV0QAH_Vz_nPQwtplHNiucUgE
"""

import ipywidgets as widgets
from IPython.display import display, clear_output
import pandas as pd
import numpy as np
import pickle
from xgboost import XGBClassifier
from sklearn.model_selection import train_test_split

# Load preprocessing objects and trained models
with open('preprocessing_objects.pkl', 'rb') as f:
    preprocessing = pickle.load(f)

with open('trained_models.pkl', 'rb') as f:
    models = pickle.load(f)

# Load the original dataset
data = pd.read_csv('data.csv')

# Preprocess the data
X = data.drop('loan_status', axis=1)
y = data['loan_status']

for column, encoder in preprocessing['label_encoders'].items():
    if column in X.columns:
        X[column] = encoder.transform(X[column])

X_scaled = preprocessing['scaler'].transform(X)

# Split the data
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

# Train XGBoost model
xgb_model = XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss')
xgb_model.fit(X_train, y_train)

# Add XGBoost model to the models dictionary
models['xgboost'] = xgb_model

# Save updated models
with open('trained_models.pkl', 'wb') as f:
    pickle.dump(models, f)

def create_prediction_interface():
    # Create input widgets for all features
    person_age = widgets.IntText(description='Age:', min=18, max=120)
    person_income = widgets.IntText(description='Income ($):', min=0)
    personhomeownership = widgets.Dropdown(
        options=['RENT', 'OWN', 'MORTGAGE'],
        description='Home Owner:',
        value='RENT'
    )
    personemplength = widgets.FloatText(description='Emp Length:', min=0)
    loan_intent = widgets.Dropdown(
        options=['PERSONAL', 'EDUCATION', 'MEDICAL', 'VENTURE', 'HOMEIMPROVEMENT', 'DEBTCONSOLIDATION'],
        description='Loan Intent:',
        value='PERSONAL'
    )
    loan_grade = widgets.Dropdown(
        options=['A', 'B', 'C', 'D', 'E', 'F', 'G'],
        description='Loan Grade:',
        value='A'
    )
    loan_amnt = widgets.FloatText(description='Loan Amt ($):', min=0)
    loanintrate = widgets.FloatText(description='Interest (%):', min=0, max=100)
    loanpercentincome = widgets.FloatText(description='% of Income:', min=0, max=100)
    cbpersondefaultonfile = widgets.Dropdown(
        options=['Y', 'N'],
        description='Past Default:',
        value='N'
    )
    cbpresoncredhistlength = widgets.FloatText(description='Credit Hist:', min=0)

    # Create prediction button
    predict_button = widgets.Button(description='Predict Default Risk')
    output = widgets.Output()

    def on_predict_button_clicked(b):
        with output:
            clear_output()

            # Collect all inputs into a dictionary
            input_data = {
                'person_age': person_age.value,
                'person_income': person_income.value,
                'personhomeownership': personhomeownership.value,
                'personemplength': personemplength.value,
                'loan_intent': loan_intent.value,
                'loan_grade': loan_grade.value,
                'loan_amnt': loan_amnt.value,
                'loanintrate': loanintrate.value,
                'loanpercentincome': loanpercentincome.value,
                'cbpersondefaultonfile': cbpersondefaultonfile.value,
                'cbpresoncredhistlength': cbpresoncredhistlength.value
            }

            # Validate inputs
            if any(value == 0 or value is None for value in input_data.values()):
                print("‚ùå Error: All fields must be filled out")
                return

            # Create DataFrame with single row of input data
            input_df = pd.DataFrame([input_data])

            # Apply preprocessing
            for column, encoder in preprocessing['label_encoders'].items():
                if column in input_df.columns:
                    input_df[column] = encoder.transform(input_df[column])

            # Scale features
            input_scaled = preprocessing['scaler'].transform(input_df)

            # Ensure that the input_scaled has column names matching the training data
            input_scaled = pd.DataFrame(input_scaled, columns=input_df.columns)

            # Make predictions
            lr_prob = models['logistic_regression'].predict_proba(input_scaled)[0][1]
            rf_prob = models['random_forest'].predict_proba(input_scaled)[0][1]
            xgb_prob = models['xgboost'].predict_proba(input_scaled)[0][1]

            # Display results
            print("\nüéØ Prediction Results:")
            print("-" * 50)
            print(f"Logistic Regression Default Probability: {lr_prob:.1%}")
            print(f"Random Forest Default Probability: {rf_prob:.1%}")
            print(f"XGBoost Default Probability: {xgb_prob:.1%}")
            print("-" * 50)

            # Risk assessment
            avg_prob = (lr_prob + rf_prob + xgb_prob) / 3
            if avg_prob < 0.3:
                print("Risk Assessment: üü¢ Low Risk")
            elif avg_prob < 0.7:
                print("Risk Assessment: üü° Medium Risk")
            else:
                print("Risk Assessment: üî¥ High Risk")

            # Feature importance analysis for this prediction
            if avg_prob > 0.5:
                print("\n‚ö†Ô∏è Key Risk Factors:")
                feature_importance = pd.DataFrame({
                    'feature': input_df.columns,
                    'value': input_df.values[0],
                    'importance': models['xgboost'].feature_importances_
                })
                feature_importance = feature_importance.sort_values('importance', ascending=False)
                for _, row in feature_importance.head(3).iterrows():
                    print(f"- {row['feature']}: {row['value']}")

    # Connect button to function
    predict_button.on_click(on_predict_button_clicked)

    # Create interface layout
    input_widgets = [
        person_age, person_income, personhomeownership, personemplength,
        loan_intent, loan_grade, loan_amnt, loanintrate, loanpercentincome,
        cbpersondefaultonfile, cbpresoncredhistlength
    ]

    # Display all widgets
    print("üíº Loan Default Risk Predictor")
    print("Fill in all fields and click 'Predict Default Risk'")
    print("-" * 50)

    for widget in input_widgets:
        display(widget)
    display(predict_button)
    display(output)

# Create and display the interface
create_prediction_interface()

# Update helper function for making predictions programmatically
def predict_loan_default(input_data):
    """
    Make predictions using all models

    Parameters:
    input_data (dict): Dictionary containing all required features

    Returns:
    dict: Containing predictions from all models
    """
    # Create DataFrame with single row
    input_df = pd.DataFrame([input_data])

    # Apply preprocessing
    for column, encoder in preprocessing['label_encoders'].items():
        if column in input_df.columns:
            input_df[column] = encoder.transform(input_df[column])

    # Scale features
    input_scaled = preprocessing['scaler'].transform(input_df)

    # Ensure that the input_scaled has column names matching the training data
    input_scaled = pd.DataFrame(input_scaled, columns=input_df.columns)

    # Make predictions
    lr_prob = models['logistic_regression'].predict_proba(input_scaled)[0][1]
    rf_prob = models['random_forest'].predict_proba(input_scaled)[0][1]
    xgb_prob = models['xgboost'].predict_proba(input_scaled)[0][1]

    return {
        'logistic_regression_probability': lr_prob,
        'random_forest_probability': rf_prob,
        'xgboost_probability': xgb_prob,
        'average_probability': (lr_prob + rf_prob + xgb_prob) / 3
    }

print("\nüìã Example Prediction Using Helper Function:")
print("-" * 50)
example_input = {
    'person_age': 30,
    'person_income': 50000,
    'personhomeownership': 'RENT',
    'personemplength': 5,
    'loan_intent': 'PERSONAL',
    'loan_grade': 'B',
    'loan_amnt': 10000,
    'loanintrate': 10,
    'loanpercentincome': 20,
    'cbpersondefaultonfile': 'N',
    'cbpresoncredhistlength': 10
}
prediction = predict_loan_default(example_input)
print("Logistic Regression Probability:", f"{prediction['logistic_regression_probability']:.1%}")
print("Random Forest Probability:", f"{prediction['random_forest_probability']:.1%}")
print("XGBoost Probability:", f"{prediction['xgboost_probability']:.1%}")
print("Average Probability:", f"{prediction['average_probability']:.1%}")